{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yknzabvM_a1i"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import re\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score, cross_validate, train_test_split\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_json(\"train.json\")\n",
        "test = pd.read_json(\"test.json\")"
      ],
      "metadata": {
        "id": "yc-xRaZoAEbm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = train.drop('cuisine', axis = 1)\n",
        "y_train = pd.DataFrame(train['cuisine'])\n",
        "\n",
        "# Split the 'features' and 'Yummly' data into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_train, \n",
        "                                                    y_train , \n",
        "                                                    test_size = 0.5, \n",
        "                                                    random_state = 123)\n"
      ],
      "metadata": {
        "id": "fn_87fLDG9w9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define how the count vectorizor will 'clean' the strings of ingredients into something useful (take a list of strings and separate the elements by commas, force lowercase)\n",
        "def xform_string(str_list):\n",
        "    return \", \".join([\n",
        "        str.lower()\n",
        "        for str in str_list\n",
        "    ])\n",
        "def toUnicode(test_str):\n",
        "  res = ''.join(r'\\u{:04X}'.format(ord(chr)) for chr in test_str)\n",
        "  return res\n"
      ],
      "metadata": {
        "id": "P_W4TVWzIE0e"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing\n",
        "# regex pattern means: use unicode, recognize words with lowercase letters between 2 and 40 characters long\n",
        "vector = CountVectorizer(\n",
        "    preprocessor = xform_string,\n",
        "    analyzer = \"word\",\n",
        "    token_pattern = r\"(?u)\\b[a-z]{2,40}\\b\",\n",
        "    max_features = 500\n",
        ")\n",
        "\n",
        "vector.fit(np.concatenate([x_train.ingredients, x_test.ingredients]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvTz7TKXH88J",
        "outputId": "7b283fea-1d7b-4049-81e7-c805f1cbdf90"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(max_features=500,\n",
              "                preprocessor=<function xform_string at 0x7f6aad4f5710>,\n",
              "                token_pattern='(?u)\\\\b[a-z]{2,40}\\\\b')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = DecisionTreeClassifier(random_state = 123)\n",
        "pipe = make_pipeline(vector, model)\n",
        "pipe.fit(x_train.ingredients, y_train.cuisine)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfysnAjCJ2_w",
        "outputId": "88c7a8e7-0f79-4462-8b73-afd8514ae6bf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('countvectorizer',\n",
              "                 CountVectorizer(max_features=500,\n",
              "                                 preprocessor=<function xform_string at 0x7f6aad4f5710>,\n",
              "                                 token_pattern='(?u)\\\\b[a-z]{2,40}\\\\b')),\n",
              "                ('decisiontreeclassifier',\n",
              "                 DecisionTreeClassifier(random_state=123))])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = pipe.predict(x_test.ingredients)\n",
        "print(accuracy_score(y_test.cuisine, results))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6Etari55aFD",
        "outputId": "3c360bf5-d115-41fc-f8ff-f9959f1ae3ee"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.601850455071152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Options for our first milestone:\n",
        "1. Decide cuisine based on number of ingredients\n",
        "  \n",
        "\n",
        "*   Make  a dataframe with (id, number of ingredients, cuisine) and use decision Tree Classifier with depth = 1\n",
        "\n",
        "\n",
        "2. one hot encode ingredients, and pick a token ingredient for every type\n",
        "* Make pipeline and column transformer, then use decision tree classifier"
      ],
      "metadata": {
        "id": "J4R6LQAXAXgd"
      }
    }
  ]
}